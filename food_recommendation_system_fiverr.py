# -*- coding: utf-8 -*-
"""food_recommendation_system_fiverr.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BevdCFJymkLxZmbc40vcancqbS6HmKsp
"""

!pip install haversine
!pip install geopy
!pip install spacy
!pip install -U sentence-transformers

import pandas as pd #Used to hold the data and perform different sql operations.
import numpy as np #Used to store arrays and perform operations on it.
import matplotlib.pyplot as plt #Used for Visualisation of graphs and plots.
import seaborn as sns #Used for better visualisation and plots.
import haversine as hs #The Haversine (or great circle) distance is the angular distance between two points on the surface of a sphere. The first coordinate of each point is assumed to be the latitude, the second is the longitude, given in radians.
from geopy.geocoders import Nominatim #Nominatim uses OpenStreetMap data to find locations on Earth by name and address (geocoding).
import nltk # Used for NLP Processing
import string #Used for using string functions
from nltk.corpus import stopwords #Getting the list of stopwords
nltk.download('stopwords') #Downloading the stopwords
from sklearn.cluster import KMeans

from sentence_transformers import SentenceTransformer, util
model = SentenceTransformer('all-MiniLM-L12-v2')

#Importing the Dataset
df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/food_recommend_fiver/zomato.csv')

"""# **Data Understanding**

url: url of that restaurants w.r.t zomato

address: address of that restaurants

name: stores the name of restaurants

online_order: indicates whether online ordering is available in the restaurant or not

book_table: indicates whether table booking option available or not

rate: contains the overall rating of the restaurant out of 5

votes: contains total number of rating for the restaurant as of a particular date

phone: stores the contact number of restaurants

location: contains the neighborhood in which the restaurant is located

rest_type: indicates the category of restaurant

dish_liked: dishes people liked in the restaurant

cuisines: stores the type of cuisines served by the restaurant

approx_cost(for two people): contains the cost for two people

reviews_list: contains different reviews given to the restaurants

menu_item: contains list of menus available in the restaurant

listed_in(type): stores the type of meal

listed_in(city): contains the neighborhood in which the restaurant is listed
"""

df.head()

df.info()

df.describe()

"""# **Data Preprocessing**"""

df.columns

#Dropping Columns not Important
df.drop(['url','phone', 'menu_item', 'listed_in(city)','dish_liked','votes','book_table','online_order','address','rest_type'],axis=1,inplace=True)

#Renaming the Columns
df.rename(columns={'rate':'ratings','approx_cost(for two people)':'approx_cost_for_two_people','name':'restaurant_name'},inplace=True)

#Check for duplicated data
df[df.duplicated()]

#Dropping the duplicates as they are of no use
df.drop_duplicates(inplace=True)

def filter_rate(str_rate): #Function to pre-process ratings into a float format
    if (str_rate=='-') or (str_rate=='NEW'): # Here, I am getting rid of the unwanted values in the ratings column
        return np.nan
    else:
        str_rate=str(str_rate).split('/')[0] # e.g 4.3/5 -> ['4.3', '5'] -> float(4.3) -> 4.3
    return float(str_rate)

df['ratings'] = df['ratings'].apply(filter_rate) #applying the filter rate function

df['approx_cost_for_two_people'] = df['approx_cost_for_two_people'].str.replace(',', '').astype(float) #Preprocess the cost from string to float format

df.dropna(subset=['location','cuisines','ratings'],inplace=True) #Dropping the NA Values

df.isnull().sum()

grouped_by_ratings = df.groupby('restaurant_name')['restaurant_name','ratings'].mean() #Calculating the mean of the ratings for each unique restaurant
df['mean_rating'] = 0

for index, row in grouped_by_ratings.iterrows():
    df['mean_rating'][df['restaurant_name'] == index] = row['ratings'] #Assigning the mean ratings to the respected restaurants

df['mean_rating'] = df['mean_rating'].round(2)

df.describe()

"""# **EDA**"""

df['restaurant_name'].nunique()

#Distribution of Restaurant Rating 
fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5))
sns.distplot(df.ratings,kde=False,color = 'g',ax =ax,bins=20);
ax.axvline(df.ratings.mean(), 0, 1, color='r', label='Mean')
ax.legend();
ax.set_ylabel('Count',size=20)
ax.set_xlabel('Rate',size=20)
ax.set_title('Distribution(count) of Restaurant rating',size=20);
# Top 10 Rated Restaurants
df_rating = df.drop_duplicates(subset='restaurant_name')
df_rating = df_rating.sort_values(by='mean_rating', ascending=False).head(10)
plt.figure(figsize=(7,5))
sns.barplot(data=df_rating, x='mean_rating', y='restaurant_name', palette='RdBu')
plt.title('Top Rated 10 Restaurants');

plt.figure(figsize = (10, 8))
sns.distplot(df['ratings'])
plt.title("Distribution of rate", fontsize=20, fontweight='bold')
plt.show()

"""# **Restaurants Recommendations**"""

def get_unique_cuisine_dict(df): #Function to get the unique restaurants with their mean rating, cuisines and location.
    unique_cuisines_for_each_rest = {}
    #Get all Unique Restaurants
    unique_restaurants = df['restaurant_name'].unique()
    for unique_rest in unique_restaurants:
        list_of_unique_cuisines=[]
        list_of_feat=[]
        for list_of_cuisines in list(df[df['restaurant_name'] == unique_rest]['cuisines']): #Loop for to get the cuisines from all the time periods for each restaurant
            list_of_cuisines = [cuisine.strip() for cuisine in list_of_cuisines.split(',')]
            list_of_unique_cuisines = list_of_unique_cuisines + list_of_cuisines
        list_of_unique_cuisines = list(set(list_of_unique_cuisines)) #To get the unique cuisines for each unique restaurant
        list_of_feat.append(df[df['restaurant_name'] == unique_rest]['mean_rating'].iloc[0]) #Appending the mean rating for unique restaurant
        list_of_feat.append(list_of_unique_cuisines) #Appending the unique cuisines for unique restaurant
        list_of_feat.append(df[df['restaurant_name'] == unique_rest]['location'].iloc[0]) #To get the location of unique restaurant.
        unique_cuisines_for_each_rest[unique_rest] = list_of_feat
    return unique_cuisines_for_each_rest

def prepare_location(df): #Function to get unique location/address 
    unique_locations = list(df['location'].unique())
    locations = pd.DataFrame(unique_locations,columns=['location'])
    locations['full_location'] = locations['location'] + ', Bangalore, Karnataka, India'
    return locations

def calculate_rest_geo_location(locations,geolocator): #Function to Calculate the geo-locations - Latitude and Longitude
    lat_lon=[]
    for location in locations['full_location']:
        location = geolocator.geocode(location)
        if location is None:
            lat_lon.append(np.nan)
        else:    
            geo=(location.latitude,location.longitude)
            lat_lon.append(geo)
    locations['lat_lon'] = lat_lon
    return locations

def calculate_user_geo_location(location,geolocator):#Function to Calculate the geo-locations - Latitude and Longitude for input user location
    location = geolocator.geocode(location)
    if location is None:
        return np.nan
    else:
        geo = (location.latitude,location.longitude)
        return geo

def get_overall_unique_cuisines(unique_cuisines_for_each_rest): #Get Unique Cuisines over all the restaurants
    list_of_overall_unique_cuisines=[]
    for key,value in unique_cuisines_for_each_rest.items():
        list_of_overall_unique_cuisines = list_of_overall_unique_cuisines + value[1]
    list_of_overall_unique_cuisines  = list(set(list_of_overall_unique_cuisines))
    return list_of_overall_unique_cuisines

def get_similar_cuisine(model,ic,list_of_overall_unique_cuisines):#Using Transformer to get the similar existing cuisines based on the input cuisines
    cuis_score_df=pd.DataFrame(columns=['cuisines','scores'])
    for cuis in list_of_overall_unique_cuisines:
        cuis_score_dict={}
        ic_vector = model.encode(ic)
        cuis_vector = model.encode(cuis)
        score = util.cos_sim(ic_vector,cuis_vector)
        cuis_score_dict['cuisines'] = cuis
        cuis_score_dict['scores'] = float(score)
        cuis_score_df = cuis_score_df.append(cuis_score_dict,ignore_index=True)
    cuis_score_df = cuis_score_df[cuis_score_df['scores'] > 0.45]
    #cuis_score_df.sort_values(by='scores',ascending=False,inplace=True)
    if not cuis_score_df.empty:
        return list(cuis_score_df['cuisines'].values)
    else:
        return None

def find_existing_cuisines_from_input(input_cuisines,model,list_of_overall_unique_cuisines): #find existing cuisines, new cuisines and process them accordingly
    list_find_cuisines_for = []
    cuis_to_be_added = []
    for ic in input_cuisines:
        if ic not in list_of_overall_unique_cuisines:
            list_find_cuisines_for.append(ic)
            found_cuis = get_similar_cuisine(model,ic,list_of_overall_unique_cuisines)

            if not(found_cuis is None):
                cuis_to_be_added = cuis_to_be_added + found_cuis
    input_cuisines = [ic for ic in input_cuisines if ic not in list_find_cuisines_for]
    if len(cuis_to_be_added) != 0:
        input_cuisines = input_cuisines + cuis_to_be_added
    input_cuisines = list(set(input_cuisines))
    return input_cuisines

def recommend(unique_cuisines_for_each_rest,input): #Recommending restaurants based on cuisines and ratings
    input_cuisines = input[0]
    input_cuisines = [cuisine.lower() for cuisine in input_cuisines]
    df_recommends=pd.DataFrame(columns=['restaurant','restaurant_ratings','present_cuisines_count','present_cuisines'])
    for rest,values in unique_cuisines_for_each_rest.items():
        recommend_rest_dict={}
        rest_cuisines = [cuisine.lower() for cuisine in values[1]]
        present_cuisines = [cuisine for cuisine in input_cuisines if cuisine in rest_cuisines] #Get only the cuisines from the restaurant which is in input list of cuisines
        present_cuisines_count = len(present_cuisines)
        if (present_cuisines_count > 0) and (values[0] >= 3.5): # Recommending restaurants which contains cuisines > 0 and ratings >= 3.5
            recommend_rest_dict['restaurant'] = rest
            recommend_rest_dict['present_cuisines_count'] = present_cuisines_count
            recommend_rest_dict['present_cuisines'] = present_cuisines
            recommend_rest_dict['restaurant_ratings'] = values[0]
            recommend_rest_dict['location'] = values[2]
            df_recommends = df_recommends.append(recommend_rest_dict,ignore_index=True)
    df_recommends.sort_values(by=['present_cuisines_count'],ascending=False,inplace=True)
    return df_recommends

def recommend_nearest_restaurants(locations_with_rest_coor,df_recommends,input_location_coor,k_model): #Recommend restaurants based on the distance neares to the user location
    list_of_dist = []
    input_loc_cluster = k_model.predict([[input_location_coor[0],input_location_coor[1]]])[0]
    locations_with_rest_coor_clus = locations_with_rest_coor[locations_with_rest_coor['cluster'] == input_loc_cluster]
    df_recommends[df_recommends['location'].apply(lambda x: True if x in locations_with_rest_coor_clus['location'] else False)]
    return df_recommends

def prepare_features_for_k_means(lat_lon):
    lat=[]
    lon=[]
    for tup in lat_lon:
        if isinstance(tup,tuple):
            lat.append(tup[0])
            lon.append(tup[1])
        else:
            lat.append(np.nan)
            lon.append(np.nan)
    return lat,lon

unique_cuisines_for_each_rest = get_unique_cuisine_dict(df)
locations = prepare_location(df)

geolocator=Nominatim(user_agent="app")
locations_with_rest_coor = calculate_rest_geo_location(locations,geolocator)

locations_with_rest_coor.dropna(subset=['lat_lon'],inplace=True)

locations_with_rest_coor = pd.read_csv('/content/locations_with_rest_coor.csv')

locations_with_rest_coor.head()

list_of_overall_unique_cuisines = get_overall_unique_cuisines(unique_cuisines_for_each_rest)

locations_with_rest_coor['lat'],locations_with_rest_coor['lon'] = prepare_features_for_k_means(locations_with_rest_coor.lat_lon)

#Creating models for k from 2 to 14
inertia = []
for k in range(2,15):
    k_model = KMeans(n_clusters=k, random_state=12).fit(locations_with_rest_coor[['lat','lon']])
    inertia.append(k_model.inertia_)

#Plotting the inertia of the models    
#Here we can choose k = 8, using the elbow Method
k_values = range(2,15)
plt.plot(k_values, inertia, 'o-')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')

k_model = KMeans(n_clusters=8).fit(locations_with_rest_coor[['lat','lon']])

locations_with_rest_coor['cluster'] = k_model.predict(locations_with_rest_coor[['lat','lon']])

input = [['choclate corn','bread butter','fruits'],'Kothnur, Bangalore, Karnataka, India']

input_cuisines = find_existing_cuisines_from_input(input[0],model,list_of_overall_unique_cuisines)
input[0] = input_cuisines

if len(input) !=0:
    df_recommends = recommend(unique_cuisines_for_each_rest,input)
    if df_recommends.empty:
        df_final_recommends=None
        print("No Recommendations found for the following input cuisines: ",input[0])
    else:
        input_location = input[1]
        input_location_coor = calculate_user_geo_location(input_location,geolocator)
        df_final_recommends = recommend_nearest_restaurants(locations_with_rest_coor,df_recommends,input_location_coor,k_model)

df_final_recommends

df_final_recommends